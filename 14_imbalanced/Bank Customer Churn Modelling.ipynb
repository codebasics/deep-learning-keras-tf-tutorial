{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv('Churn_Modelling.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['RowNumber','CustomerId','Surname'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 13)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Exited==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2037, 13)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Exited==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].replace({'Female':0,'Male':1},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale=['CreditScore','Age','Balance','EstimatedSalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "df[cols_to_scale]=scaler.fit_transform(df[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['Exited'],axis=1)\n",
    "y=df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 12)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 12)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(X_train,y_train,X_test,y_test,loss,weights):\n",
    "\n",
    "    model=keras.Sequential([\n",
    "        keras.layers.Dense(20,input_shape=(12,),activation='relu'),\n",
    "        keras.layers.Dense(40,activation='relu'),\n",
    "        keras.layers.Dense(80,activation='relu'),\n",
    "        keras.layers.Dense(40,activation='relu'),\n",
    "        keras.layers.Dense(20,activation='relu'),\n",
    "        keras.layers.Dense(1,activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=loss,\n",
    "                  metrics=['accuracy'])\n",
    "    if weights==-1:\n",
    "        model.fit(X_train,y_train,epochs=100)\n",
    "    else:\n",
    "        model.fit(X_train,y_train,epochs=100,class_weight=weights)\n",
    "        \n",
    "    print(model.evaluate(X_test,y_test))\n",
    "    \n",
    "    y_pred=model.predict(X_test)\n",
    "    y_pred=np.round(y_pred)\n",
    "    \n",
    "    print('Classification Report: \\n',classification_report(y_test,y_pred))\n",
    "    \n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.4976 - acc: 0.7946\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4667 - acc: 0.7968\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4454 - acc: 0.8075\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4213 - acc: 0.8195\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4073 - acc: 0.8253\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3908 - acc: 0.8332\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3783 - acc: 0.8390\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3697 - acc: 0.8454\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3669 - acc: 0.8447\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3617 - acc: 0.8504\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3580 - acc: 0.85180s - loss: 0.3517 - acc: 0.85\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3545 - acc: 0.8529\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3517 - acc: 0.8544\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3496 - acc: 0.8529\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3456 - acc: 0.8591\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3442 - acc: 0.8605\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3414 - acc: 0.8602\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3435 - acc: 0.8601\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3384 - acc: 0.8643\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3379 - acc: 0.8630\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3353 - acc: 0.8654\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3339 - acc: 0.8635\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3318 - acc: 0.86550s - loss: 0.3328 - acc: 0.865\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3304 - acc: 0.8648\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3309 - acc: 0.8655\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3284 - acc: 0.8669\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3280 - acc: 0.8685\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3298 - acc: 0.8665\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3254 - acc: 0.8695\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3265 - acc: 0.8666\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3238 - acc: 0.8711\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3240 - acc: 0.8666\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3228 - acc: 0.8702\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3217 - acc: 0.8685\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3194 - acc: 0.8709\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3188 - acc: 0.8710\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3217 - acc: 0.8702\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3167 - acc: 0.8724\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3206 - acc: 0.8701\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3168 - acc: 0.8711\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3142 - acc: 0.8725\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3143 - acc: 0.8763\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3152 - acc: 0.8735\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3111 - acc: 0.8764\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3116 - acc: 0.8750\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3105 - acc: 0.8731\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3116 - acc: 0.8729\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3081 - acc: 0.8759\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3052 - acc: 0.8788\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3063 - acc: 0.8748\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3073 - acc: 0.87490s - loss: 0.3080 - acc: 0.875\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3031 - acc: 0.8781\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3056 - acc: 0.8784\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3041 - acc: 0.8764\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.2986 - acc: 0.8804\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3010 - acc: 0.8799\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.2972 - acc: 0.8820\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.2991 - acc: 0.8804\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.2990 - acc: 0.8813\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.2934 - acc: 0.8832\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.2949 - acc: 0.8836\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.2924 - acc: 0.8830\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.2929 - acc: 0.8850\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.2922 - acc: 0.8815\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.2942 - acc: 0.8824\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.2883 - acc: 0.8851\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.2922 - acc: 0.8819\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.2863 - acc: 0.8841\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.2864 - acc: 0.8855\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.2833 - acc: 0.8871\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.2819 - acc: 0.8884\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.2799 - acc: 0.8871\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.2815 - acc: 0.88810s - loss: 0.2808 - acc: 0.88\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.2828 - acc: 0.8841\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.2794 - acc: 0.8875\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.2793 - acc: 0.8855\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.2765 - acc: 0.8889\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.2744 - acc: 0.8886\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.2728 - acc: 0.8907\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.2694 - acc: 0.8919\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.2688 - acc: 0.8924\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.2704 - acc: 0.8904\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.2698 - acc: 0.8932\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.2701 - acc: 0.8909\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.2686 - acc: 0.8940\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.2663 - acc: 0.8913\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.2664 - acc: 0.89200s - loss: 0.2696 - acc: 0.\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.2622 - acc: 0.8941\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.2660 - acc: 0.8920\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.2578 - acc: 0.8978\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.2612 - acc: 0.8945\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.2598 - acc: 0.8946\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.2546 - acc: 0.8990\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.2635 - acc: 0.8920\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.2548 - acc: 0.8969\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.2555 - acc: 0.8941\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.2571 - acc: 0.8934\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.2533 - acc: 0.8971\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.2493 - acc: 0.8991\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.2537 - acc: 0.8961\n",
      "2000/2000 [==============================] - 0s 129us/sample - loss: 0.4242 - acc: 0.8515\n",
      "[0.424184907913208, 0.8515]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      1595\n",
      "           1       0.68      0.50      0.58       405\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.78      0.72      0.74      2000\n",
      "weighted avg       0.84      0.85      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=ANN(X_train,y_train,X_test,y_test,'binary_crossentropy',-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "for element in yp:\n",
    "    if element > 0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9394    0\n",
       "898     1\n",
       "2398    0\n",
       "5906    0\n",
       "2343    0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      1595\n",
      "           1       0.68      0.47      0.55       405\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.78      0.71      0.73      2000\n",
      "weighted avg       0.84      0.85      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print (classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 : Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_0,count_class_1=df.Exited.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7963"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_class_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2037"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_0=df[df['Exited']==0]\n",
    "df_class_1=df[df['Exited']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2037\n",
      "0    2037\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_class_0_under=df_class_0.sample(count_class_1)\n",
    "\n",
    "df_test_under=pd.concat([df_class_0_under,df_class_1],axis=0)\n",
    "df_test_under.shape\n",
    "print(df_test_under.Exited.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_test_under.drop('Exited',axis=1)\n",
    "y=df_test_under['Exited']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=15,stratify=y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3259, 12)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(815, 12)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1630\n",
       "0    1629\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3259/3259 [==============================] - 0s 79us/sample - loss: 0.6831 - acc: 0.5492\n",
      "Epoch 2/100\n",
      "3259/3259 [==============================] - 0s 33us/sample - loss: 0.6552 - acc: 0.6272\n",
      "Epoch 3/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.6167 - acc: 0.6643\n",
      "Epoch 4/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.5867 - acc: 0.6956\n",
      "Epoch 5/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.5641 - acc: 0.7076\n",
      "Epoch 6/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.5309 - acc: 0.7324\n",
      "Epoch 7/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.5106 - acc: 0.7469\n",
      "Epoch 8/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.5033 - acc: 0.7518\n",
      "Epoch 9/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.5023 - acc: 0.7542\n",
      "Epoch 10/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4955 - acc: 0.7610\n",
      "Epoch 11/100\n",
      "3259/3259 [==============================] - 0s 34us/sample - loss: 0.4930 - acc: 0.7622\n",
      "Epoch 12/100\n",
      "3259/3259 [==============================] - 0s 34us/sample - loss: 0.4831 - acc: 0.7637\n",
      "Epoch 13/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4795 - acc: 0.7717\n",
      "Epoch 14/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4836 - acc: 0.7686\n",
      "Epoch 15/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4719 - acc: 0.7702\n",
      "Epoch 16/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4737 - acc: 0.7714\n",
      "Epoch 17/100\n",
      "3259/3259 [==============================] - 0s 36us/sample - loss: 0.4728 - acc: 0.7720\n",
      "Epoch 18/100\n",
      "3259/3259 [==============================] - 0s 36us/sample - loss: 0.4675 - acc: 0.7693\n",
      "Epoch 19/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4686 - acc: 0.7717\n",
      "Epoch 20/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4625 - acc: 0.7745\n",
      "Epoch 21/100\n",
      "3259/3259 [==============================] - 0s 34us/sample - loss: 0.4652 - acc: 0.7717\n",
      "Epoch 22/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4646 - acc: 0.7766\n",
      "Epoch 23/100\n",
      "3259/3259 [==============================] - 0s 36us/sample - loss: 0.4557 - acc: 0.7803\n",
      "Epoch 24/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4545 - acc: 0.7852\n",
      "Epoch 25/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4490 - acc: 0.7788\n",
      "Epoch 26/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4478 - acc: 0.7892\n",
      "Epoch 27/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4469 - acc: 0.7824\n",
      "Epoch 28/100\n",
      "3259/3259 [==============================] - 0s 36us/sample - loss: 0.4405 - acc: 0.7920\n",
      "Epoch 29/100\n",
      "3259/3259 [==============================] - 0s 36us/sample - loss: 0.4421 - acc: 0.7917\n",
      "Epoch 30/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4378 - acc: 0.7910\n",
      "Epoch 31/100\n",
      "3259/3259 [==============================] - 0s 37us/sample - loss: 0.4388 - acc: 0.7852\n",
      "Epoch 32/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4335 - acc: 0.7855\n",
      "Epoch 33/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4368 - acc: 0.7840\n",
      "Epoch 34/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4275 - acc: 0.7987\n",
      "Epoch 35/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4283 - acc: 0.7990\n",
      "Epoch 36/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4282 - acc: 0.7910\n",
      "Epoch 37/100\n",
      "3259/3259 [==============================] - 0s 36us/sample - loss: 0.4207 - acc: 0.8036\n",
      "Epoch 38/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4188 - acc: 0.7996\n",
      "Epoch 39/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4170 - acc: 0.8073\n",
      "Epoch 40/100\n",
      "3259/3259 [==============================] - 0s 36us/sample - loss: 0.4151 - acc: 0.8045\n",
      "Epoch 41/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4105 - acc: 0.8061\n",
      "Epoch 42/100\n",
      "3259/3259 [==============================] - 0s 34us/sample - loss: 0.4094 - acc: 0.8110\n",
      "Epoch 43/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4070 - acc: 0.8085\n",
      "Epoch 44/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.3996 - acc: 0.8159\n",
      "Epoch 45/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4009 - acc: 0.8180\n",
      "Epoch 46/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.4003 - acc: 0.8107\n",
      "Epoch 47/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.3954 - acc: 0.8217\n",
      "Epoch 48/100\n",
      "3259/3259 [==============================] - 0s 40us/sample - loss: 0.3929 - acc: 0.8193\n",
      "Epoch 49/100\n",
      "3259/3259 [==============================] - 0s 47us/sample - loss: 0.4038 - acc: 0.8116\n",
      "Epoch 50/100\n",
      "3259/3259 [==============================] - 0s 34us/sample - loss: 0.3878 - acc: 0.8199\n",
      "Epoch 51/100\n",
      "3259/3259 [==============================] - 0s 36us/sample - loss: 0.3825 - acc: 0.8269\n",
      "Epoch 52/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.3841 - acc: 0.8211\n",
      "Epoch 53/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.3795 - acc: 0.8276\n",
      "Epoch 54/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.3833 - acc: 0.8199\n",
      "Epoch 55/100\n",
      "3259/3259 [==============================] - 0s 34us/sample - loss: 0.3818 - acc: 0.8266\n",
      "Epoch 56/100\n",
      "3259/3259 [==============================] - 0s 34us/sample - loss: 0.3766 - acc: 0.8263\n",
      "Epoch 57/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.3773 - acc: 0.8269\n",
      "Epoch 58/100\n",
      "3259/3259 [==============================] - 0s 34us/sample - loss: 0.3688 - acc: 0.8312\n",
      "Epoch 59/100\n",
      "3259/3259 [==============================] - 0s 34us/sample - loss: 0.3707 - acc: 0.8322\n",
      "Epoch 60/100\n",
      "3259/3259 [==============================] - 0s 33us/sample - loss: 0.3627 - acc: 0.8334\n",
      "Epoch 61/100\n",
      "3259/3259 [==============================] - 0s 34us/sample - loss: 0.3663 - acc: 0.8349\n",
      "Epoch 62/100\n",
      "3259/3259 [==============================] - 0s 34us/sample - loss: 0.3597 - acc: 0.8374\n",
      "Epoch 63/100\n",
      "3259/3259 [==============================] - 0s 33us/sample - loss: 0.3463 - acc: 0.8509\n",
      "Epoch 64/100\n",
      "3259/3259 [==============================] - 0s 33us/sample - loss: 0.3515 - acc: 0.8417\n",
      "Epoch 65/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.3518 - acc: 0.8395\n",
      "Epoch 66/100\n",
      "3259/3259 [==============================] - 0s 50us/sample - loss: 0.3453 - acc: 0.8438\n",
      "Epoch 67/100\n",
      "3259/3259 [==============================] - 0s 36us/sample - loss: 0.3460 - acc: 0.8426\n",
      "Epoch 68/100\n",
      "3259/3259 [==============================] - 0s 36us/sample - loss: 0.3391 - acc: 0.8530\n",
      "Epoch 69/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.3410 - acc: 0.8447\n",
      "Epoch 70/100\n",
      "3259/3259 [==============================] - 0s 34us/sample - loss: 0.3414 - acc: 0.8450\n",
      "Epoch 71/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.3293 - acc: 0.8530\n",
      "Epoch 72/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.3278 - acc: 0.8598\n",
      "Epoch 73/100\n",
      "3259/3259 [==============================] - 0s 36us/sample - loss: 0.3243 - acc: 0.8555\n",
      "Epoch 74/100\n",
      "3259/3259 [==============================] - 0s 36us/sample - loss: 0.3307 - acc: 0.8552\n",
      "Epoch 75/100\n",
      "3259/3259 [==============================] - 0s 36us/sample - loss: 0.3235 - acc: 0.8576\n",
      "Epoch 76/100\n",
      "3259/3259 [==============================] - 0s 36us/sample - loss: 0.3208 - acc: 0.8564\n",
      "Epoch 77/100\n",
      "3259/3259 [==============================] - 0s 36us/sample - loss: 0.3226 - acc: 0.8613\n",
      "Epoch 78/100\n",
      "3259/3259 [==============================] - 0s 36us/sample - loss: 0.3182 - acc: 0.8573\n",
      "Epoch 79/100\n",
      "3259/3259 [==============================] - 0s 36us/sample - loss: 0.3142 - acc: 0.8592\n",
      "Epoch 80/100\n",
      "3259/3259 [==============================] - 0s 36us/sample - loss: 0.3152 - acc: 0.8628\n",
      "Epoch 81/100\n",
      "3259/3259 [==============================] - 0s 36us/sample - loss: 0.3044 - acc: 0.8638\n",
      "Epoch 82/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.3142 - acc: 0.8542\n",
      "Epoch 83/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.3109 - acc: 0.8638\n",
      "Epoch 84/100\n",
      "3259/3259 [==============================] - 0s 34us/sample - loss: 0.3050 - acc: 0.8613\n",
      "Epoch 85/100\n",
      "3259/3259 [==============================] - 0s 33us/sample - loss: 0.3070 - acc: 0.8610\n",
      "Epoch 86/100\n",
      "3259/3259 [==============================] - 0s 34us/sample - loss: 0.2990 - acc: 0.8711\n",
      "Epoch 87/100\n",
      "3259/3259 [==============================] - 0s 34us/sample - loss: 0.2999 - acc: 0.8699\n",
      "Epoch 88/100\n",
      "3259/3259 [==============================] - 0s 42us/sample - loss: 0.2840 - acc: 0.8770\n",
      "Epoch 89/100\n",
      "3259/3259 [==============================] - 0s 42us/sample - loss: 0.2897 - acc: 0.8693\n",
      "Epoch 90/100\n",
      "3259/3259 [==============================] - 0s 42us/sample - loss: 0.2934 - acc: 0.8699\n",
      "Epoch 91/100\n",
      "3259/3259 [==============================] - 0s 40us/sample - loss: 0.2865 - acc: 0.8693\n",
      "Epoch 92/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.2819 - acc: 0.8745\n",
      "Epoch 93/100\n",
      "3259/3259 [==============================] - 0s 34us/sample - loss: 0.2833 - acc: 0.8736\n",
      "Epoch 94/100\n",
      "3259/3259 [==============================] - 0s 33us/sample - loss: 0.2898 - acc: 0.8727\n",
      "Epoch 95/100\n",
      "3259/3259 [==============================] - 0s 33us/sample - loss: 0.2750 - acc: 0.8834\n",
      "Epoch 96/100\n",
      "3259/3259 [==============================] - 0s 33us/sample - loss: 0.2738 - acc: 0.8776\n",
      "Epoch 97/100\n",
      "3259/3259 [==============================] - 0s 35us/sample - loss: 0.2666 - acc: 0.8819\n",
      "Epoch 98/100\n",
      "3259/3259 [==============================] - 0s 37us/sample - loss: 0.2669 - acc: 0.8825\n",
      "Epoch 99/100\n",
      "3259/3259 [==============================] - 0s 42us/sample - loss: 0.2669 - acc: 0.8855\n",
      "Epoch 100/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.2695 - acc: 0.8834\n",
      "815/815 [==============================] - 0s 102us/sample - loss: 0.7763 - acc: 0.7129\n",
      "[0.776274278631971, 0.7128834]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.71       408\n",
      "           1       0.71      0.71      0.71       407\n",
      "\n",
      "    accuracy                           0.71       815\n",
      "   macro avg       0.71      0.71      0.71       815\n",
      "weighted avg       0.71      0.71      0.71       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds=ANN(X_train,y_train,X_test,y_test,'binary_crossentropy',-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2 : Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 2037)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_class_0,count_class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_1_over=df_class_1.sample(count_class_0,replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7963\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_1_over.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_0.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7963\n",
       "0    7963\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_over=pd.concat([df_class_0,df_class_1_over],axis=0)\n",
    "df_test_over.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_test_over.drop('Exited',axis=1)\n",
    "y=df_test_over['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=15,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12740, 12)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3186,)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6370\n",
       "0    6370\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12740/12740 [==============================] - 1s 51us/sample - loss: 0.6408 - acc: 0.6351\n",
      "Epoch 2/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5466 - acc: 0.7243\n",
      "Epoch 3/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.5070 - acc: 0.7542\n",
      "Epoch 4/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.4963 - acc: 0.7581\n",
      "Epoch 5/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.4855 - acc: 0.7629\n",
      "Epoch 6/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.4772 - acc: 0.7675\n",
      "Epoch 7/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.4745 - acc: 0.7673\n",
      "Epoch 8/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.4681 - acc: 0.7728\n",
      "Epoch 9/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.4603 - acc: 0.7755\n",
      "Epoch 10/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.4538 - acc: 0.7834\n",
      "Epoch 11/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.4487 - acc: 0.7856\n",
      "Epoch 12/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.4445 - acc: 0.7907\n",
      "Epoch 13/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.4423 - acc: 0.7900\n",
      "Epoch 14/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.4354 - acc: 0.7933\n",
      "Epoch 15/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.4310 - acc: 0.7981\n",
      "Epoch 16/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.4273 - acc: 0.7994\n",
      "Epoch 17/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.4259 - acc: 0.8006\n",
      "Epoch 18/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.4192 - acc: 0.8043\n",
      "Epoch 19/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.4189 - acc: 0.8024\n",
      "Epoch 20/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.4158 - acc: 0.8042\n",
      "Epoch 21/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.4131 - acc: 0.8060\n",
      "Epoch 22/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.4121 - acc: 0.8050\n",
      "Epoch 23/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.4047 - acc: 0.8088\n",
      "Epoch 24/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.4047 - acc: 0.8104\n",
      "Epoch 25/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.4028 - acc: 0.8133\n",
      "Epoch 26/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.3984 - acc: 0.8123\n",
      "Epoch 27/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.3961 - acc: 0.8137\n",
      "Epoch 28/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.3903 - acc: 0.8166\n",
      "Epoch 29/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.3848 - acc: 0.8201\n",
      "Epoch 30/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.3806 - acc: 0.8230\n",
      "Epoch 31/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.3820 - acc: 0.8205\n",
      "Epoch 32/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.3757 - acc: 0.8257\n",
      "Epoch 33/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.3685 - acc: 0.8277\n",
      "Epoch 34/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.3681 - acc: 0.8265\n",
      "Epoch 35/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.3619 - acc: 0.8334\n",
      "Epoch 36/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.3592 - acc: 0.8331\n",
      "Epoch 37/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3583 - acc: 0.8334\n",
      "Epoch 38/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.3511 - acc: 0.8388\n",
      "Epoch 39/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.3543 - acc: 0.8330\n",
      "Epoch 40/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.3443 - acc: 0.8412\n",
      "Epoch 41/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.3444 - acc: 0.8443\n",
      "Epoch 42/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.3335 - acc: 0.8440\n",
      "Epoch 43/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.3353 - acc: 0.8458\n",
      "Epoch 44/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.3303 - acc: 0.8498\n",
      "Epoch 45/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.3222 - acc: 0.8537\n",
      "Epoch 46/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.3250 - acc: 0.8503\n",
      "Epoch 47/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.3164 - acc: 0.8560\n",
      "Epoch 48/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.3120 - acc: 0.85890s - loss: 0.3021 - acc: 0\n",
      "Epoch 49/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.3074 - acc: 0.8606\n",
      "Epoch 50/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.3097 - acc: 0.8610\n",
      "Epoch 51/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.3091 - acc: 0.8604\n",
      "Epoch 52/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.3024 - acc: 0.8637\n",
      "Epoch 53/100\n",
      "12740/12740 [==============================] - 1s 40us/sample - loss: 0.2969 - acc: 0.8650\n",
      "Epoch 54/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.2933 - acc: 0.8692\n",
      "Epoch 55/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.2926 - acc: 0.8705\n",
      "Epoch 56/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.2908 - acc: 0.8701\n",
      "Epoch 57/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.2886 - acc: 0.8698\n",
      "Epoch 58/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.2821 - acc: 0.8727\n",
      "Epoch 59/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.2802 - acc: 0.8750\n",
      "Epoch 60/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.2735 - acc: 0.8768\n",
      "Epoch 61/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.2728 - acc: 0.8786\n",
      "Epoch 62/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.2726 - acc: 0.8793\n",
      "Epoch 63/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.2694 - acc: 0.8779\n",
      "Epoch 64/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.2697 - acc: 0.8781\n",
      "Epoch 65/100\n",
      "12740/12740 [==============================] - 1s 39us/sample - loss: 0.2604 - acc: 0.8856\n",
      "Epoch 66/100\n",
      "12740/12740 [==============================] - 1s 40us/sample - loss: 0.2593 - acc: 0.8885\n",
      "Epoch 67/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.2594 - acc: 0.8873\n",
      "Epoch 68/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.2558 - acc: 0.8898\n",
      "Epoch 69/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.2543 - acc: 0.8880\n",
      "Epoch 70/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.2563 - acc: 0.8886\n",
      "Epoch 71/100\n",
      "12740/12740 [==============================] - 1s 40us/sample - loss: 0.2541 - acc: 0.8863\n",
      "Epoch 72/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2440 - acc: 0.8931\n",
      "Epoch 73/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2388 - acc: 0.8958\n",
      "Epoch 74/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2416 - acc: 0.8947\n",
      "Epoch 75/100\n",
      "12740/12740 [==============================] - 1s 42us/sample - loss: 0.2493 - acc: 0.8894\n",
      "Epoch 76/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2352 - acc: 0.8969\n",
      "Epoch 77/100\n",
      "12740/12740 [==============================] - 1s 42us/sample - loss: 0.2364 - acc: 0.8980\n",
      "Epoch 78/100\n",
      "12740/12740 [==============================] - 1s 42us/sample - loss: 0.2396 - acc: 0.8969\n",
      "Epoch 79/100\n",
      "12740/12740 [==============================] - 1s 40us/sample - loss: 0.2310 - acc: 0.8998\n",
      "Epoch 80/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.2310 - acc: 0.9006\n",
      "Epoch 81/100\n",
      "12740/12740 [==============================] - 0s 39us/sample - loss: 0.2289 - acc: 0.8996\n",
      "Epoch 82/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.2287 - acc: 0.9009\n",
      "Epoch 83/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.2431 - acc: 0.8915\n",
      "Epoch 84/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.2123 - acc: 0.9082\n",
      "Epoch 85/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.2142 - acc: 0.9092\n",
      "Epoch 86/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.2456 - acc: 0.8973\n",
      "Epoch 87/100\n",
      "12740/12740 [==============================] - 0s 39us/sample - loss: 0.2167 - acc: 0.9087\n",
      "Epoch 88/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.2054 - acc: 0.9141\n",
      "Epoch 89/100\n",
      "12740/12740 [==============================] - 0s 39us/sample - loss: 0.2060 - acc: 0.9122\n",
      "Epoch 90/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.2160 - acc: 0.9065\n",
      "Epoch 91/100\n",
      "12740/12740 [==============================] - 0s 39us/sample - loss: 0.2076 - acc: 0.9133\n",
      "Epoch 92/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.2025 - acc: 0.9128\n",
      "Epoch 93/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.1994 - acc: 0.9147\n",
      "Epoch 94/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.2022 - acc: 0.9122\n",
      "Epoch 95/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.2074 - acc: 0.9148\n",
      "Epoch 96/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.2048 - acc: 0.9130\n",
      "Epoch 97/100\n",
      "12740/12740 [==============================] - 0s 39us/sample - loss: 0.1937 - acc: 0.9206\n",
      "Epoch 98/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.1910 - acc: 0.9199\n",
      "Epoch 99/100\n",
      "12740/12740 [==============================] - 0s 39us/sample - loss: 0.2029 - acc: 0.9134\n",
      "Epoch 100/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.1884 - acc: 0.9214\n",
      "3186/3186 [==============================] - 0s 49us/sample - loss: 0.3919 - acc: 0.8713\n",
      "[0.391873656917651, 0.87131196]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87      1593\n",
      "           1       0.84      0.92      0.88      1593\n",
      "\n",
      "    accuracy                           0.87      3186\n",
      "   macro avg       0.87      0.87      0.87      3186\n",
      "weighted avg       0.87      0.87      0.87      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds=ANN(X_train,y_train,X_test,y_test,'binary_crossentropy',-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3 : SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Exited',axis='columns')\n",
    "y=df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7963\n",
       "0    7963\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote=SMOTE(sampling_strategy='minority')\n",
    "X_sm,y_sm=smote.fit_sample(X,y)\n",
    "\n",
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_sm,y_sm,random_state=15,stratify=y_sm,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6370\n",
       "0    6370\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12740/12740 [==============================] - 1s 55us/sample - loss: 0.6234 - acc: 0.6460\n",
      "Epoch 2/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.5266 - acc: 0.7370\n",
      "Epoch 3/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.4863 - acc: 0.7646\n",
      "Epoch 4/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.4697 - acc: 0.7748\n",
      "Epoch 5/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.4600 - acc: 0.7808\n",
      "Epoch 6/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.4494 - acc: 0.7862\n",
      "Epoch 7/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.4356 - acc: 0.7951\n",
      "Epoch 8/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.4337 - acc: 0.79850s - loss: 0.4344 - acc: 0.798\n",
      "Epoch 9/100\n",
      "12740/12740 [==============================] - 0s 39us/sample - loss: 0.4245 - acc: 0.7998\n",
      "Epoch 10/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.4220 - acc: 0.8027\n",
      "Epoch 11/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.4170 - acc: 0.8045\n",
      "Epoch 12/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.4200 - acc: 0.8034\n",
      "Epoch 13/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.4160 - acc: 0.8093\n",
      "Epoch 14/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.4122 - acc: 0.8104\n",
      "Epoch 15/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.4073 - acc: 0.8107\n",
      "Epoch 16/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.4073 - acc: 0.8096\n",
      "Epoch 17/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.4030 - acc: 0.8143\n",
      "Epoch 18/100\n",
      "12740/12740 [==============================] - 0s 39us/sample - loss: 0.4002 - acc: 0.8168\n",
      "Epoch 19/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.4005 - acc: 0.8133\n",
      "Epoch 20/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3967 - acc: 0.8170\n",
      "Epoch 21/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3960 - acc: 0.8197\n",
      "Epoch 22/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3925 - acc: 0.8192\n",
      "Epoch 23/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3883 - acc: 0.8228\n",
      "Epoch 24/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3838 - acc: 0.8236\n",
      "Epoch 25/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3842 - acc: 0.8214\n",
      "Epoch 26/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3803 - acc: 0.8250\n",
      "Epoch 27/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3780 - acc: 0.8268\n",
      "Epoch 28/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3757 - acc: 0.8307\n",
      "Epoch 29/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3724 - acc: 0.8289\n",
      "Epoch 30/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3731 - acc: 0.8293\n",
      "Epoch 31/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3673 - acc: 0.8314\n",
      "Epoch 32/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3664 - acc: 0.8333\n",
      "Epoch 33/100\n",
      "12740/12740 [==============================] - 0s 39us/sample - loss: 0.3620 - acc: 0.8322\n",
      "Epoch 34/100\n",
      "12740/12740 [==============================] - 0s 39us/sample - loss: 0.3578 - acc: 0.8360\n",
      "Epoch 35/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3557 - acc: 0.8349\n",
      "Epoch 36/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3505 - acc: 0.8409\n",
      "Epoch 37/100\n",
      "12740/12740 [==============================] - 0s 39us/sample - loss: 0.3536 - acc: 0.8365\n",
      "Epoch 38/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3499 - acc: 0.8422\n",
      "Epoch 39/100\n",
      "12740/12740 [==============================] - 0s 39us/sample - loss: 0.3469 - acc: 0.8441\n",
      "Epoch 40/100\n",
      "12740/12740 [==============================] - 0s 39us/sample - loss: 0.3404 - acc: 0.8475\n",
      "Epoch 41/100\n",
      "12740/12740 [==============================] - 0s 39us/sample - loss: 0.3385 - acc: 0.8476\n",
      "Epoch 42/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3363 - acc: 0.8507\n",
      "Epoch 43/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3314 - acc: 0.8537\n",
      "Epoch 44/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3305 - acc: 0.8493\n",
      "Epoch 45/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3257 - acc: 0.8537\n",
      "Epoch 46/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3261 - acc: 0.8555\n",
      "Epoch 47/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3221 - acc: 0.8567\n",
      "Epoch 48/100\n",
      "12740/12740 [==============================] - 1s 43us/sample - loss: 0.3149 - acc: 0.8586\n",
      "Epoch 49/100\n",
      "12740/12740 [==============================] - 1s 44us/sample - loss: 0.3161 - acc: 0.8613\n",
      "Epoch 50/100\n",
      "12740/12740 [==============================] - 1s 43us/sample - loss: 0.3152 - acc: 0.8616\n",
      "Epoch 51/100\n",
      "12740/12740 [==============================] - 1s 40us/sample - loss: 0.3062 - acc: 0.8637\n",
      "Epoch 52/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.3042 - acc: 0.8648\n",
      "Epoch 53/100\n",
      "12740/12740 [==============================] - 1s 43us/sample - loss: 0.3033 - acc: 0.8659\n",
      "Epoch 54/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.3019 - acc: 0.8676\n",
      "Epoch 55/100\n",
      "12740/12740 [==============================] - 1s 45us/sample - loss: 0.2966 - acc: 0.8725\n",
      "Epoch 56/100\n",
      "12740/12740 [==============================] - 1s 40us/sample - loss: 0.3004 - acc: 0.8652\n",
      "Epoch 57/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.2934 - acc: 0.8714\n",
      "Epoch 58/100\n",
      "12740/12740 [==============================] - 1s 42us/sample - loss: 0.2879 - acc: 0.8741\n",
      "Epoch 59/100\n",
      "12740/12740 [==============================] - 1s 44us/sample - loss: 0.2859 - acc: 0.87390s - loss: 0.2890 - acc: \n",
      "Epoch 60/100\n",
      "12740/12740 [==============================] - 1s 46us/sample - loss: 0.2851 - acc: 0.8756\n",
      "Epoch 61/100\n",
      "12740/12740 [==============================] - 1s 47us/sample - loss: 0.2793 - acc: 0.8772\n",
      "Epoch 62/100\n",
      "12740/12740 [==============================] - 1s 51us/sample - loss: 0.2794 - acc: 0.8779\n",
      "Epoch 63/100\n",
      "12740/12740 [==============================] - 1s 50us/sample - loss: 0.2828 - acc: 0.8739\n",
      "Epoch 64/100\n",
      "12740/12740 [==============================] - ETA: 0s - loss: 0.2737 - acc: 0.882 - 1s 48us/sample - loss: 0.2730 - acc: 0.8816\n",
      "Epoch 65/100\n",
      "12740/12740 [==============================] - 1s 48us/sample - loss: 0.2721 - acc: 0.8808\n",
      "Epoch 66/100\n",
      "12740/12740 [==============================] - 1s 47us/sample - loss: 0.2677 - acc: 0.8820\n",
      "Epoch 67/100\n",
      "12740/12740 [==============================] - 1s 49us/sample - loss: 0.2686 - acc: 0.8816\n",
      "Epoch 68/100\n",
      "12740/12740 [==============================] - 1s 47us/sample - loss: 0.2630 - acc: 0.8872\n",
      "Epoch 69/100\n",
      "12740/12740 [==============================] - 1s 45us/sample - loss: 0.2671 - acc: 0.8832\n",
      "Epoch 70/100\n",
      "12740/12740 [==============================] - 1s 44us/sample - loss: 0.2660 - acc: 0.8843\n",
      "Epoch 71/100\n",
      "12740/12740 [==============================] - 1s 46us/sample - loss: 0.2588 - acc: 0.8914\n",
      "Epoch 72/100\n",
      "12740/12740 [==============================] - 1s 47us/sample - loss: 0.2548 - acc: 0.8900\n",
      "Epoch 73/100\n",
      "12740/12740 [==============================] - 1s 47us/sample - loss: 0.2542 - acc: 0.8902\n",
      "Epoch 74/100\n",
      "12740/12740 [==============================] - 1s 45us/sample - loss: 0.2573 - acc: 0.8891\n",
      "Epoch 75/100\n",
      "12740/12740 [==============================] - 1s 46us/sample - loss: 0.2530 - acc: 0.8913\n",
      "Epoch 76/100\n",
      "12740/12740 [==============================] - 1s 46us/sample - loss: 0.2513 - acc: 0.8915\n",
      "Epoch 77/100\n",
      "12740/12740 [==============================] - 1s 45us/sample - loss: 0.2463 - acc: 0.8939\n",
      "Epoch 78/100\n",
      "12740/12740 [==============================] - 1s 45us/sample - loss: 0.2481 - acc: 0.8949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2445 - acc: 0.8931\n",
      "Epoch 80/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2426 - acc: 0.8966\n",
      "Epoch 81/100\n",
      "12740/12740 [==============================] - 1s 40us/sample - loss: 0.2340 - acc: 0.9018\n",
      "Epoch 82/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2418 - acc: 0.8961\n",
      "Epoch 83/100\n",
      "12740/12740 [==============================] - 1s 40us/sample - loss: 0.2369 - acc: 0.8985\n",
      "Epoch 84/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2411 - acc: 0.8955\n",
      "Epoch 85/100\n",
      "12740/12740 [==============================] - 1s 40us/sample - loss: 0.2346 - acc: 0.8994\n",
      "Epoch 86/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2325 - acc: 0.9005\n",
      "Epoch 87/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2312 - acc: 0.9000\n",
      "Epoch 88/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2291 - acc: 0.9020\n",
      "Epoch 89/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2311 - acc: 0.9004\n",
      "Epoch 90/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2282 - acc: 0.9049\n",
      "Epoch 91/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2209 - acc: 0.9037\n",
      "Epoch 92/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2263 - acc: 0.9013\n",
      "Epoch 93/100\n",
      "12740/12740 [==============================] - 1s 40us/sample - loss: 0.2201 - acc: 0.9071\n",
      "Epoch 94/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2214 - acc: 0.9066\n",
      "Epoch 95/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2178 - acc: 0.9097\n",
      "Epoch 96/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2204 - acc: 0.9058\n",
      "Epoch 97/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2139 - acc: 0.9089\n",
      "Epoch 98/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2254 - acc: 0.9034\n",
      "Epoch 99/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2164 - acc: 0.9073\n",
      "Epoch 100/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.2094 - acc: 0.9100\n",
      "3186/3186 [==============================] - 0s 52us/sample - loss: 0.4530 - acc: 0.8371\n",
      "[0.45304608193494506, 0.8370998]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84      1593\n",
      "           1       0.83      0.84      0.84      1593\n",
      "\n",
      "    accuracy                           0.84      3186\n",
      "   macro avg       0.84      0.84      0.84      3186\n",
      "weighted avg       0.84      0.84      0.84      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds=ANN(X_train,y_train,X_test,y_test,'binary_crossentropy',-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4: use of Ensemble with undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_class0=df[df.Exited==0]\n",
    "df3_class1=df[df.Exited==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 13)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_class0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9091801669121256"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7963/2037"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2037, 13)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_class1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch(df_majority,df_minority,start,end):\n",
    "    df_train=pd.concat([df_majority[start:end],df_minority],axis=0)\n",
    "    \n",
    "    X=df_train.drop('Exited',axis='columns')\n",
    "    y=df_train['Exited']\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2037\n",
       "0    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_en,y_en=get_train_batch(df3_class0,df3_class1,0,2037)\n",
    "y_en.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_en,y_en,random_state=15,stratify=y_en,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3259/3259 [==============================] - 0s 111us/sample - loss: 0.6840 - acc: 0.5483\n",
      "Epoch 2/100\n",
      "3259/3259 [==============================] - 0s 42us/sample - loss: 0.6401 - acc: 0.6358\n",
      "Epoch 3/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.6077 - acc: 0.6729\n",
      "Epoch 4/100\n",
      "3259/3259 [==============================] - 0s 42us/sample - loss: 0.5869 - acc: 0.6812\n",
      "Epoch 5/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.5638 - acc: 0.6968\n",
      "Epoch 6/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.5494 - acc: 0.7088\n",
      "Epoch 7/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.5287 - acc: 0.7358\n",
      "Epoch 8/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.5150 - acc: 0.7487\n",
      "Epoch 9/100\n",
      "3259/3259 [==============================] - 0s 42us/sample - loss: 0.5153 - acc: 0.7423\n",
      "Epoch 10/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.5013 - acc: 0.7527\n",
      "Epoch 11/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.4947 - acc: 0.7536\n",
      "Epoch 12/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4940 - acc: 0.7576\n",
      "Epoch 13/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.4940 - acc: 0.7597\n",
      "Epoch 14/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.4801 - acc: 0.7643\n",
      "Epoch 15/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.4818 - acc: 0.7597\n",
      "Epoch 16/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.4790 - acc: 0.7665\n",
      "Epoch 17/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.4778 - acc: 0.7634\n",
      "Epoch 18/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4806 - acc: 0.7573\n",
      "Epoch 19/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.4725 - acc: 0.7640\n",
      "Epoch 20/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.4686 - acc: 0.7732\n",
      "Epoch 21/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4712 - acc: 0.7696\n",
      "Epoch 22/100\n",
      "3259/3259 [==============================] - 0s 42us/sample - loss: 0.4680 - acc: 0.7693\n",
      "Epoch 23/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.4674 - acc: 0.7720\n",
      "Epoch 24/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.4580 - acc: 0.7760\n",
      "Epoch 25/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.4678 - acc: 0.7653\n",
      "Epoch 26/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.4611 - acc: 0.7754\n",
      "Epoch 27/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.4584 - acc: 0.7785\n",
      "Epoch 28/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.4590 - acc: 0.7723\n",
      "Epoch 29/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.4577 - acc: 0.7742\n",
      "Epoch 30/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.4450 - acc: 0.7818\n",
      "Epoch 31/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.4418 - acc: 0.7818\n",
      "Epoch 32/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.4458 - acc: 0.7874\n",
      "Epoch 33/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.4480 - acc: 0.7821\n",
      "Epoch 34/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.4392 - acc: 0.7895\n",
      "Epoch 35/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.4383 - acc: 0.7901\n",
      "Epoch 36/100\n",
      "3259/3259 [==============================] - 0s 48us/sample - loss: 0.4405 - acc: 0.7904\n",
      "Epoch 37/100\n",
      "3259/3259 [==============================] - 0s 52us/sample - loss: 0.4381 - acc: 0.7898\n",
      "Epoch 38/100\n",
      "3259/3259 [==============================] - 0s 50us/sample - loss: 0.4433 - acc: 0.7858\n",
      "Epoch 39/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.4306 - acc: 0.7877\n",
      "Epoch 40/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4235 - acc: 0.7987\n",
      "Epoch 41/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.4319 - acc: 0.78800s - loss: 0.4339 - acc: 0.79\n",
      "Epoch 42/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4225 - acc: 0.8015\n",
      "Epoch 43/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.4219 - acc: 0.79470s - loss: 0.4247 - acc: 0.793\n",
      "Epoch 44/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.4307 - acc: 0.7929\n",
      "Epoch 45/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.4286 - acc: 0.7956\n",
      "Epoch 46/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.4234 - acc: 0.8048\n",
      "Epoch 47/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.4198 - acc: 0.8033\n",
      "Epoch 48/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.4146 - acc: 0.8076\n",
      "Epoch 49/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.4153 - acc: 0.8067\n",
      "Epoch 50/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.4127 - acc: 0.8033\n",
      "Epoch 51/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.4147 - acc: 0.7993\n",
      "Epoch 52/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.4068 - acc: 0.8101\n",
      "Epoch 53/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.4092 - acc: 0.8091\n",
      "Epoch 54/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.4068 - acc: 0.8055\n",
      "Epoch 55/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.4069 - acc: 0.8052\n",
      "Epoch 56/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.4064 - acc: 0.8095\n",
      "Epoch 57/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.4032 - acc: 0.8144\n",
      "Epoch 58/100\n",
      "3259/3259 [==============================] - 0s 42us/sample - loss: 0.3967 - acc: 0.8141\n",
      "Epoch 59/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4004 - acc: 0.8147\n",
      "Epoch 60/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.3977 - acc: 0.8171\n",
      "Epoch 61/100\n",
      "3259/3259 [==============================] - 0s 42us/sample - loss: 0.4054 - acc: 0.8131\n",
      "Epoch 62/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.3913 - acc: 0.8217\n",
      "Epoch 63/100\n",
      "3259/3259 [==============================] - 0s 42us/sample - loss: 0.3931 - acc: 0.8199\n",
      "Epoch 64/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.3916 - acc: 0.8217\n",
      "Epoch 65/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3919 - acc: 0.8245\n",
      "Epoch 66/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.3884 - acc: 0.8205\n",
      "Epoch 67/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3850 - acc: 0.8220\n",
      "Epoch 68/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.3881 - acc: 0.8233\n",
      "Epoch 69/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.3831 - acc: 0.8260\n",
      "Epoch 70/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3801 - acc: 0.8230\n",
      "Epoch 71/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3806 - acc: 0.8260\n",
      "Epoch 72/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.3795 - acc: 0.8217\n",
      "Epoch 73/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.3765 - acc: 0.8297\n",
      "Epoch 74/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.3782 - acc: 0.8220\n",
      "Epoch 75/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3796 - acc: 0.8279\n",
      "Epoch 76/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3741 - acc: 0.8279\n",
      "Epoch 77/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.3744 - acc: 0.8312\n",
      "Epoch 78/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.3695 - acc: 0.8352\n",
      "Epoch 79/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3650 - acc: 0.8355\n",
      "Epoch 80/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.3668 - acc: 0.8272\n",
      "Epoch 81/100\n",
      "3259/3259 [==============================] - 0s 42us/sample - loss: 0.3636 - acc: 0.8331\n",
      "Epoch 82/100\n",
      "3259/3259 [==============================] - 0s 41us/sample - loss: 0.3631 - acc: 0.8309\n",
      "Epoch 83/100\n",
      "3259/3259 [==============================] - 0s 42us/sample - loss: 0.3611 - acc: 0.8334\n",
      "Epoch 84/100\n",
      "3259/3259 [==============================] - 0s 41us/sample - loss: 0.3549 - acc: 0.8365\n",
      "Epoch 85/100\n",
      "3259/3259 [==============================] - 0s 42us/sample - loss: 0.3610 - acc: 0.8361\n",
      "Epoch 86/100\n",
      "3259/3259 [==============================] - 0s 41us/sample - loss: 0.3629 - acc: 0.8392\n",
      "Epoch 87/100\n",
      "3259/3259 [==============================] - 0s 42us/sample - loss: 0.3515 - acc: 0.8377\n",
      "Epoch 88/100\n",
      "3259/3259 [==============================] - 0s 41us/sample - loss: 0.3508 - acc: 0.8414\n",
      "Epoch 89/100\n",
      "3259/3259 [==============================] - 0s 41us/sample - loss: 0.3545 - acc: 0.8392\n",
      "Epoch 90/100\n",
      "3259/3259 [==============================] - 0s 41us/sample - loss: 0.3597 - acc: 0.8368\n",
      "Epoch 91/100\n",
      "3259/3259 [==============================] - 0s 41us/sample - loss: 0.3446 - acc: 0.8429\n",
      "Epoch 92/100\n",
      "3259/3259 [==============================] - 0s 42us/sample - loss: 0.3437 - acc: 0.8426\n",
      "Epoch 93/100\n",
      "3259/3259 [==============================] - 0s 42us/sample - loss: 0.3430 - acc: 0.8432\n",
      "Epoch 94/100\n",
      "3259/3259 [==============================] - 0s 42us/sample - loss: 0.3444 - acc: 0.8383\n",
      "Epoch 95/100\n",
      "3259/3259 [==============================] - 0s 42us/sample - loss: 0.3436 - acc: 0.8432\n",
      "Epoch 96/100\n",
      "3259/3259 [==============================] - 0s 41us/sample - loss: 0.3410 - acc: 0.8432\n",
      "Epoch 97/100\n",
      "3259/3259 [==============================] - 0s 41us/sample - loss: 0.3403 - acc: 0.8377\n",
      "Epoch 98/100\n",
      "3259/3259 [==============================] - 0s 42us/sample - loss: 0.3340 - acc: 0.8463\n",
      "Epoch 99/100\n",
      "3259/3259 [==============================] - 0s 41us/sample - loss: 0.3301 - acc: 0.8509\n",
      "Epoch 100/100\n",
      "3259/3259 [==============================] - 0s 41us/sample - loss: 0.3415 - acc: 0.8414\n",
      "815/815 [==============================] - 0s 169us/sample - loss: 0.5682 - acc: 0.7472\n",
      "[0.5681733072535392, 0.7472393]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76       408\n",
      "           1       0.77      0.70      0.74       407\n",
      "\n",
      "    accuracy                           0.75       815\n",
      "   macro avg       0.75      0.75      0.75       815\n",
      "weighted avg       0.75      0.75      0.75       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred1=ANN(X_train,y_train,X_test,y_test,'binary_crossentropy',-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2037\n",
       "0    2036\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_en_1,y_en_1=get_train_batch(df3_class0,df3_class1,2038,4074)\n",
    "y_en_1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_en_1,y_en_1,random_state=15,stratify=y_en_1,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3258/3258 [==============================] - 0s 107us/sample - loss: 0.6897 - acc: 0.5319\n",
      "Epoch 2/100\n",
      "3258/3258 [==============================] - 0s 43us/sample - loss: 0.6559 - acc: 0.6179\n",
      "Epoch 3/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.6284 - acc: 0.6578\n",
      "Epoch 4/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.6173 - acc: 0.6593\n",
      "Epoch 5/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.6025 - acc: 0.6777\n",
      "Epoch 6/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.5985 - acc: 0.6765\n",
      "Epoch 7/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.5854 - acc: 0.6900\n",
      "Epoch 8/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.5801 - acc: 0.6971\n",
      "Epoch 9/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.5772 - acc: 0.7072\n",
      "Epoch 10/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.5779 - acc: 0.7017\n",
      "Epoch 11/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.5639 - acc: 0.7112\n",
      "Epoch 12/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.5611 - acc: 0.7149\n",
      "Epoch 13/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.5475 - acc: 0.7253\n",
      "Epoch 14/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.5370 - acc: 0.7277\n",
      "Epoch 15/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.5284 - acc: 0.7327\n",
      "Epoch 16/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.5256 - acc: 0.7345\n",
      "Epoch 17/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.5202 - acc: 0.7373\n",
      "Epoch 18/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.5109 - acc: 0.7354\n",
      "Epoch 19/100\n",
      "3258/3258 [==============================] - 0s 46us/sample - loss: 0.4988 - acc: 0.7560\n",
      "Epoch 20/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.4951 - acc: 0.7581\n",
      "Epoch 21/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.4905 - acc: 0.7594\n",
      "Epoch 22/100\n",
      "3258/3258 [==============================] - 0s 46us/sample - loss: 0.4875 - acc: 0.7560\n",
      "Epoch 23/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.4825 - acc: 0.7624\n",
      "Epoch 24/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.4770 - acc: 0.7683\n",
      "Epoch 25/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4766 - acc: 0.7716\n",
      "Epoch 26/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4731 - acc: 0.7759\n",
      "Epoch 27/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.4679 - acc: 0.7799\n",
      "Epoch 28/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.4626 - acc: 0.7759\n",
      "Epoch 29/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4592 - acc: 0.7778\n",
      "Epoch 30/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4582 - acc: 0.7855\n",
      "Epoch 31/100\n",
      "3258/3258 [==============================] - 0s 46us/sample - loss: 0.4622 - acc: 0.7762\n",
      "Epoch 32/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4581 - acc: 0.7836\n",
      "Epoch 33/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4557 - acc: 0.7818\n",
      "Epoch 34/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4488 - acc: 0.7876\n",
      "Epoch 35/100\n",
      "3258/3258 [==============================] - 0s 46us/sample - loss: 0.4520 - acc: 0.7781\n",
      "Epoch 36/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4474 - acc: 0.7891\n",
      "Epoch 37/100\n",
      "3258/3258 [==============================] - 0s 47us/sample - loss: 0.4482 - acc: 0.7815\n",
      "Epoch 38/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4412 - acc: 0.7947\n",
      "Epoch 39/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.4438 - acc: 0.7904\n",
      "Epoch 40/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4411 - acc: 0.7904\n",
      "Epoch 41/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4360 - acc: 0.7904\n",
      "Epoch 42/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.4372 - acc: 0.7861\n",
      "Epoch 43/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4383 - acc: 0.7925\n",
      "Epoch 44/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.4319 - acc: 0.7977\n",
      "Epoch 45/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4340 - acc: 0.7940\n",
      "Epoch 46/100\n",
      "3258/3258 [==============================] - ETA: 0s - loss: 0.4306 - acc: 0.796 - 0s 45us/sample - loss: 0.4341 - acc: 0.7947\n",
      "Epoch 47/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4280 - acc: 0.7950\n",
      "Epoch 48/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4274 - acc: 0.8042\n",
      "Epoch 49/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4267 - acc: 0.8017\n",
      "Epoch 50/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.4237 - acc: 0.7993\n",
      "Epoch 51/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4183 - acc: 0.8023\n",
      "Epoch 52/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4191 - acc: 0.8020\n",
      "Epoch 53/100\n",
      "3258/3258 [==============================] - 0s 46us/sample - loss: 0.4204 - acc: 0.7977\n",
      "Epoch 54/100\n",
      "3258/3258 [==============================] - 0s 46us/sample - loss: 0.4195 - acc: 0.7990\n",
      "Epoch 55/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4168 - acc: 0.8063\n",
      "Epoch 56/100\n",
      "3258/3258 [==============================] - 0s 46us/sample - loss: 0.4221 - acc: 0.8039\n",
      "Epoch 57/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.4165 - acc: 0.8002\n",
      "Epoch 58/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4209 - acc: 0.8045\n",
      "Epoch 59/100\n",
      "3258/3258 [==============================] - 0s 46us/sample - loss: 0.4098 - acc: 0.8079\n",
      "Epoch 60/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4153 - acc: 0.8045\n",
      "Epoch 61/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4043 - acc: 0.8063\n",
      "Epoch 62/100\n",
      "3258/3258 [==============================] - 0s 46us/sample - loss: 0.3993 - acc: 0.8125\n",
      "Epoch 63/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.4070 - acc: 0.8097\n",
      "Epoch 64/100\n",
      "3258/3258 [==============================] - 0s 46us/sample - loss: 0.4042 - acc: 0.8091\n",
      "Epoch 65/100\n",
      "3258/3258 [==============================] - 0s 46us/sample - loss: 0.4033 - acc: 0.8158\n",
      "Epoch 66/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.3960 - acc: 0.8177\n",
      "Epoch 67/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.3972 - acc: 0.8091\n",
      "Epoch 68/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.3991 - acc: 0.8168\n",
      "Epoch 69/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.3962 - acc: 0.8211\n",
      "Epoch 70/100\n",
      "3258/3258 [==============================] - 0s 46us/sample - loss: 0.3945 - acc: 0.8211\n",
      "Epoch 71/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.3926 - acc: 0.8229\n",
      "Epoch 72/100\n",
      "3258/3258 [==============================] - 0s 47us/sample - loss: 0.3977 - acc: 0.8149\n",
      "Epoch 73/100\n",
      "3258/3258 [==============================] - 0s 46us/sample - loss: 0.3911 - acc: 0.8183\n",
      "Epoch 74/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.3955 - acc: 0.8122\n",
      "Epoch 75/100\n",
      "3258/3258 [==============================] - 0s 47us/sample - loss: 0.3846 - acc: 0.8217\n",
      "Epoch 76/100\n",
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.3843 - acc: 0.8220\n",
      "Epoch 77/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.3833 - acc: 0.8220\n",
      "Epoch 78/100\n",
      "3258/3258 [==============================] - 0s 46us/sample - loss: 0.3871 - acc: 0.8220\n",
      "Epoch 79/100\n",
      "3258/3258 [==============================] - 0s 46us/sample - loss: 0.3767 - acc: 0.8192\n",
      "Epoch 80/100\n",
      "3258/3258 [==============================] - 0s 46us/sample - loss: 0.3809 - acc: 0.8214\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3258/3258 [==============================] - 0s 45us/sample - loss: 0.3825 - acc: 0.8217\n",
      "Epoch 82/100\n",
      "3258/3258 [==============================] - 0s 43us/sample - loss: 0.3772 - acc: 0.8232\n",
      "Epoch 83/100\n",
      "3258/3258 [==============================] - 0s 42us/sample - loss: 0.3738 - acc: 0.8281\n",
      "Epoch 84/100\n",
      "3258/3258 [==============================] - 0s 43us/sample - loss: 0.3700 - acc: 0.8275\n",
      "Epoch 85/100\n",
      "3258/3258 [==============================] - 0s 43us/sample - loss: 0.3704 - acc: 0.8297\n",
      "Epoch 86/100\n",
      "3258/3258 [==============================] - 0s 42us/sample - loss: 0.3640 - acc: 0.8324\n",
      "Epoch 87/100\n",
      "3258/3258 [==============================] - 0s 42us/sample - loss: 0.3669 - acc: 0.8284\n",
      "Epoch 88/100\n",
      "3258/3258 [==============================] - 0s 42us/sample - loss: 0.3630 - acc: 0.8312\n",
      "Epoch 89/100\n",
      "3258/3258 [==============================] - 0s 43us/sample - loss: 0.3682 - acc: 0.8269\n",
      "Epoch 90/100\n",
      "3258/3258 [==============================] - 0s 41us/sample - loss: 0.3625 - acc: 0.8333\n",
      "Epoch 91/100\n",
      "3258/3258 [==============================] - 0s 43us/sample - loss: 0.3642 - acc: 0.8290\n",
      "Epoch 92/100\n",
      "3258/3258 [==============================] - 0s 42us/sample - loss: 0.3552 - acc: 0.8352\n",
      "Epoch 93/100\n",
      "3258/3258 [==============================] - 0s 42us/sample - loss: 0.3625 - acc: 0.8330\n",
      "Epoch 94/100\n",
      "3258/3258 [==============================] - 0s 43us/sample - loss: 0.3598 - acc: 0.8382\n",
      "Epoch 95/100\n",
      "3258/3258 [==============================] - 0s 43us/sample - loss: 0.3532 - acc: 0.8343\n",
      "Epoch 96/100\n",
      "3258/3258 [==============================] - 0s 43us/sample - loss: 0.3588 - acc: 0.8339\n",
      "Epoch 97/100\n",
      "3258/3258 [==============================] - 0s 44us/sample - loss: 0.3522 - acc: 0.8373\n",
      "Epoch 98/100\n",
      "3258/3258 [==============================] - 0s 42us/sample - loss: 0.3522 - acc: 0.8343\n",
      "Epoch 99/100\n",
      "3258/3258 [==============================] - 0s 43us/sample - loss: 0.3537 - acc: 0.8339\n",
      "Epoch 100/100\n",
      "3258/3258 [==============================] - 0s 43us/sample - loss: 0.3561 - acc: 0.8367\n",
      "815/815 [==============================] - 0s 218us/sample - loss: 0.6389 - acc: 0.7387\n",
      "[0.6388828545260283, 0.7386503]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.82      0.76       407\n",
      "           1       0.78      0.66      0.72       408\n",
      "\n",
      "    accuracy                           0.74       815\n",
      "   macro avg       0.74      0.74      0.74       815\n",
      "weighted avg       0.74      0.74      0.74       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred2=ANN(X_train,y_train,X_test,y_test,'binary_crossentropy',-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2037\n",
       "0    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_en_2,y_en_2=get_train_batch(df3_class0,df3_class1,4075,6112)\n",
    "y_en_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_en_2,y_en_2,random_state=15,stratify=y_en_2,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3259/3259 [==============================] - 0s 110us/sample - loss: 0.6677 - acc: 0.6008\n",
      "Epoch 2/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.6156 - acc: 0.6698\n",
      "Epoch 3/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.6110 - acc: 0.6735\n",
      "Epoch 4/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.5800 - acc: 0.7042\n",
      "Epoch 5/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.5681 - acc: 0.7100\n",
      "Epoch 6/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.5424 - acc: 0.7327\n",
      "Epoch 7/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.5374 - acc: 0.7370\n",
      "Epoch 8/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.5236 - acc: 0.73830s - loss: 0.5212 - acc: 0.743\n",
      "Epoch 9/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.5049 - acc: 0.7564\n",
      "Epoch 10/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.5000 - acc: 0.7594\n",
      "Epoch 11/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4938 - acc: 0.7607\n",
      "Epoch 12/100\n",
      "3259/3259 [==============================] - 0s 48us/sample - loss: 0.4853 - acc: 0.7723\n",
      "Epoch 13/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.4869 - acc: 0.7699\n",
      "Epoch 14/100\n",
      "3259/3259 [==============================] - 0s 47us/sample - loss: 0.4847 - acc: 0.7677\n",
      "Epoch 15/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.4726 - acc: 0.7788\n",
      "Epoch 16/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.4733 - acc: 0.7699\n",
      "Epoch 17/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4723 - acc: 0.7732\n",
      "Epoch 18/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.4660 - acc: 0.7757\n",
      "Epoch 19/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4580 - acc: 0.7815\n",
      "Epoch 20/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4575 - acc: 0.7889\n",
      "Epoch 21/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.4554 - acc: 0.7864\n",
      "Epoch 22/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4571 - acc: 0.7895\n",
      "Epoch 23/100\n",
      "3259/3259 [==============================] - 0s 47us/sample - loss: 0.4425 - acc: 0.7944\n",
      "Epoch 24/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4456 - acc: 0.7867\n",
      "Epoch 25/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4409 - acc: 0.7993\n",
      "Epoch 26/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4395 - acc: 0.7978\n",
      "Epoch 27/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4408 - acc: 0.7901\n",
      "Epoch 28/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4334 - acc: 0.8027\n",
      "Epoch 29/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.4358 - acc: 0.7959\n",
      "Epoch 30/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.4336 - acc: 0.7990\n",
      "Epoch 31/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4301 - acc: 0.8018\n",
      "Epoch 32/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4305 - acc: 0.7947\n",
      "Epoch 33/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.4274 - acc: 0.8042\n",
      "Epoch 34/100\n",
      "3259/3259 [==============================] - 0s 47us/sample - loss: 0.4210 - acc: 0.8052\n",
      "Epoch 35/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.4196 - acc: 0.8091\n",
      "Epoch 36/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4222 - acc: 0.8042\n",
      "Epoch 37/100\n",
      "3259/3259 [==============================] - 0s 47us/sample - loss: 0.4157 - acc: 0.8067\n",
      "Epoch 38/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4119 - acc: 0.8061\n",
      "Epoch 39/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.4108 - acc: 0.8061\n",
      "Epoch 40/100\n",
      "3259/3259 [==============================] - 0s 47us/sample - loss: 0.4123 - acc: 0.8085\n",
      "Epoch 41/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4101 - acc: 0.8098\n",
      "Epoch 42/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4060 - acc: 0.8082\n",
      "Epoch 43/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.4064 - acc: 0.8190\n",
      "Epoch 44/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.4016 - acc: 0.8107\n",
      "Epoch 45/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.4041 - acc: 0.8165\n",
      "Epoch 46/100\n",
      "3259/3259 [==============================] - 0s 47us/sample - loss: 0.4002 - acc: 0.8162\n",
      "Epoch 47/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.3954 - acc: 0.8199\n",
      "Epoch 48/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.3921 - acc: 0.8199\n",
      "Epoch 49/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.3896 - acc: 0.8223\n",
      "Epoch 50/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3914 - acc: 0.8199\n",
      "Epoch 51/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3875 - acc: 0.8226\n",
      "Epoch 52/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.3880 - acc: 0.8168\n",
      "Epoch 53/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.3865 - acc: 0.8220\n",
      "Epoch 54/100\n",
      "3259/3259 [==============================] - 0s 47us/sample - loss: 0.3837 - acc: 0.8257\n",
      "Epoch 55/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.3813 - acc: 0.8214\n",
      "Epoch 56/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3771 - acc: 0.8294\n",
      "Epoch 57/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3813 - acc: 0.8236\n",
      "Epoch 58/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.3794 - acc: 0.8233\n",
      "Epoch 59/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3780 - acc: 0.8251\n",
      "Epoch 60/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3777 - acc: 0.8260\n",
      "Epoch 61/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3698 - acc: 0.8257\n",
      "Epoch 62/100\n",
      "3259/3259 [==============================] - 0s 47us/sample - loss: 0.3670 - acc: 0.8312\n",
      "Epoch 63/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3605 - acc: 0.8325\n",
      "Epoch 64/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3685 - acc: 0.8306\n",
      "Epoch 65/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.3631 - acc: 0.8319\n",
      "Epoch 66/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.3621 - acc: 0.8322\n",
      "Epoch 67/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.3499 - acc: 0.8386\n",
      "Epoch 68/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3557 - acc: 0.8383\n",
      "Epoch 69/100\n",
      "3259/3259 [==============================] - 0s 47us/sample - loss: 0.3673 - acc: 0.8395\n",
      "Epoch 70/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.3604 - acc: 0.8328\n",
      "Epoch 71/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3560 - acc: 0.8383\n",
      "Epoch 72/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.3480 - acc: 0.8398\n",
      "Epoch 73/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.3422 - acc: 0.8469\n",
      "Epoch 74/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3339 - acc: 0.8487\n",
      "Epoch 75/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.3323 - acc: 0.8518\n",
      "Epoch 76/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.3424 - acc: 0.8457\n",
      "Epoch 77/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.3356 - acc: 0.8478\n",
      "Epoch 78/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.3266 - acc: 0.8542\n",
      "Epoch 79/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.3301 - acc: 0.8493\n",
      "Epoch 80/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3243 - acc: 0.8542\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.3215 - acc: 0.8573\n",
      "Epoch 82/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3217 - acc: 0.8564\n",
      "Epoch 83/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.3278 - acc: 0.8478\n",
      "Epoch 84/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3171 - acc: 0.8601\n",
      "Epoch 85/100\n",
      "3259/3259 [==============================] - 0s 45us/sample - loss: 0.3224 - acc: 0.8582\n",
      "Epoch 86/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.3178 - acc: 0.8592\n",
      "Epoch 87/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.3046 - acc: 0.8622\n",
      "Epoch 88/100\n",
      "3259/3259 [==============================] - 0s 42us/sample - loss: 0.3103 - acc: 0.8552\n",
      "Epoch 89/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.3091 - acc: 0.8604\n",
      "Epoch 90/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.2993 - acc: 0.8668\n",
      "Epoch 91/100\n",
      "3259/3259 [==============================] - 0s 49us/sample - loss: 0.2957 - acc: 0.8628\n",
      "Epoch 92/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.2999 - acc: 0.8656\n",
      "Epoch 93/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.3104 - acc: 0.8585\n",
      "Epoch 94/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.2997 - acc: 0.8678\n",
      "Epoch 95/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.2930 - acc: 0.8693\n",
      "Epoch 96/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.2886 - acc: 0.8717\n",
      "Epoch 97/100\n",
      "3259/3259 [==============================] - 0s 43us/sample - loss: 0.2823 - acc: 0.8751\n",
      "Epoch 98/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.2833 - acc: 0.8711\n",
      "Epoch 99/100\n",
      "3259/3259 [==============================] - 0s 46us/sample - loss: 0.2859 - acc: 0.8776\n",
      "Epoch 100/100\n",
      "3259/3259 [==============================] - 0s 44us/sample - loss: 0.2851 - acc: 0.8742\n",
      "815/815 [==============================] - 0s 173us/sample - loss: 0.8191 - acc: 0.7129\n",
      "[0.8191270836657542, 0.7128834]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72       408\n",
      "           1       0.73      0.68      0.70       407\n",
      "\n",
      "    accuracy                           0.71       815\n",
      "   macro avg       0.71      0.71      0.71       815\n",
      "weighted avg       0.71      0.71      0.71       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred3=ANN(X_train,y_train,X_test,y_test,'binary_crossentropy',-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2037\n",
       "0    1851\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_en_3,y_en_3=get_train_batch(df3_class0,df3_class1,6112,7963)\n",
    "y_en_3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_en_3,y_en_3,random_state=15,stratify=y_en_3,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3110/3110 [==============================] - 0s 112us/sample - loss: 0.6637 - acc: 0.5997\n",
      "Epoch 2/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.6241 - acc: 0.6566\n",
      "Epoch 3/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.5942 - acc: 0.6839\n",
      "Epoch 4/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.5624 - acc: 0.7048\n",
      "Epoch 5/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.5362 - acc: 0.7264\n",
      "Epoch 6/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.5279 - acc: 0.7341\n",
      "Epoch 7/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.5103 - acc: 0.7424\n",
      "Epoch 8/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.4992 - acc: 0.7534\n",
      "Epoch 9/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.4916 - acc: 0.7614\n",
      "Epoch 10/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.4864 - acc: 0.7682\n",
      "Epoch 11/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.4797 - acc: 0.7720\n",
      "Epoch 12/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.4788 - acc: 0.7785\n",
      "Epoch 13/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.4747 - acc: 0.7762\n",
      "Epoch 14/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.4753 - acc: 0.7678\n",
      "Epoch 15/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.4649 - acc: 0.7762\n",
      "Epoch 16/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.4619 - acc: 0.7810\n",
      "Epoch 17/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.4638 - acc: 0.7823\n",
      "Epoch 18/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.4594 - acc: 0.7842\n",
      "Epoch 19/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.4551 - acc: 0.7884\n",
      "Epoch 20/100\n",
      "3110/3110 [==============================] - ETA: 0s - loss: 0.4504 - acc: 0.779 - 0s 47us/sample - loss: 0.4532 - acc: 0.7817\n",
      "Epoch 21/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.4479 - acc: 0.7952\n",
      "Epoch 22/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.4510 - acc: 0.7900\n",
      "Epoch 23/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.4466 - acc: 0.7859\n",
      "Epoch 24/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.4437 - acc: 0.7945\n",
      "Epoch 25/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.4543 - acc: 0.7865\n",
      "Epoch 26/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.4404 - acc: 0.7932\n",
      "Epoch 27/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.4344 - acc: 0.7942\n",
      "Epoch 28/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.4326 - acc: 0.7990\n",
      "Epoch 29/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.4346 - acc: 0.7955\n",
      "Epoch 30/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.4314 - acc: 0.8019\n",
      "Epoch 31/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.4315 - acc: 0.8026\n",
      "Epoch 32/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.4222 - acc: 0.8048\n",
      "Epoch 33/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.4263 - acc: 0.8058\n",
      "Epoch 34/100\n",
      "3110/3110 [==============================] - 0s 45us/sample - loss: 0.4251 - acc: 0.8016\n",
      "Epoch 35/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.4272 - acc: 0.7981\n",
      "Epoch 36/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.4199 - acc: 0.8055\n",
      "Epoch 37/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.4192 - acc: 0.8003\n",
      "Epoch 38/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.4168 - acc: 0.8096\n",
      "Epoch 39/100\n",
      "3110/3110 [==============================] - 0s 48us/sample - loss: 0.4292 - acc: 0.7961\n",
      "Epoch 40/100\n",
      "3110/3110 [==============================] - 0s 48us/sample - loss: 0.4183 - acc: 0.8051\n",
      "Epoch 41/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.4145 - acc: 0.8074\n",
      "Epoch 42/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.4070 - acc: 0.8100\n",
      "Epoch 43/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.4046 - acc: 0.8116\n",
      "Epoch 44/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.4054 - acc: 0.8077\n",
      "Epoch 45/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.4007 - acc: 0.8145\n",
      "Epoch 46/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.4062 - acc: 0.8154\n",
      "Epoch 47/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.3996 - acc: 0.8100\n",
      "Epoch 48/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.3972 - acc: 0.8132\n",
      "Epoch 49/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.3923 - acc: 0.8167\n",
      "Epoch 50/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.3855 - acc: 0.8238\n",
      "Epoch 51/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.3875 - acc: 0.8183\n",
      "Epoch 52/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.3886 - acc: 0.8212\n",
      "Epoch 53/100\n",
      "3110/3110 [==============================] - 0s 48us/sample - loss: 0.3821 - acc: 0.8257\n",
      "Epoch 54/100\n",
      "3110/3110 [==============================] - 0s 51us/sample - loss: 0.3851 - acc: 0.8190\n",
      "Epoch 55/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.3847 - acc: 0.8193\n",
      "Epoch 56/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.3795 - acc: 0.8257\n",
      "Epoch 57/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.3787 - acc: 0.8254\n",
      "Epoch 58/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.3808 - acc: 0.8225\n",
      "Epoch 59/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.3874 - acc: 0.8174\n",
      "Epoch 60/100\n",
      "3110/3110 [==============================] - 0s 45us/sample - loss: 0.3714 - acc: 0.8328\n",
      "Epoch 61/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.3614 - acc: 0.8376\n",
      "Epoch 62/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.3650 - acc: 0.8299\n",
      "Epoch 63/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.3602 - acc: 0.8334\n",
      "Epoch 64/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.3617 - acc: 0.8331\n",
      "Epoch 65/100\n",
      "3110/3110 [==============================] - 0s 45us/sample - loss: 0.3641 - acc: 0.8248\n",
      "Epoch 66/100\n",
      "3110/3110 [==============================] - 0s 49us/sample - loss: 0.3555 - acc: 0.8350\n",
      "Epoch 67/100\n",
      "3110/3110 [==============================] - 0s 54us/sample - loss: 0.3706 - acc: 0.8277\n",
      "Epoch 68/100\n",
      "3110/3110 [==============================] - 0s 59us/sample - loss: 0.3515 - acc: 0.8447\n",
      "Epoch 69/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.3481 - acc: 0.8415\n",
      "Epoch 70/100\n",
      "3110/3110 [==============================] - 0s 52us/sample - loss: 0.3550 - acc: 0.8347\n",
      "Epoch 71/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.3470 - acc: 0.8376\n",
      "Epoch 72/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.3523 - acc: 0.8350\n",
      "Epoch 73/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.3417 - acc: 0.8408\n",
      "Epoch 74/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.3342 - acc: 0.8421\n",
      "Epoch 75/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.3403 - acc: 0.8379\n",
      "Epoch 76/100\n",
      "3110/3110 [==============================] - ETA: 0s - loss: 0.3594 - acc: 0.823 - 0s 45us/sample - loss: 0.3560 - acc: 0.8283\n",
      "Epoch 77/100\n",
      "3110/3110 [==============================] - 0s 47us/sample - loss: 0.3400 - acc: 0.8450\n",
      "Epoch 78/100\n",
      "3110/3110 [==============================] - 0s 45us/sample - loss: 0.3298 - acc: 0.8502\n",
      "Epoch 79/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.3304 - acc: 0.8450\n",
      "Epoch 80/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.3289 - acc: 0.8457\n",
      "Epoch 81/100\n",
      "3110/3110 [==============================] - 0s 45us/sample - loss: 0.3273 - acc: 0.8441\n",
      "Epoch 82/100\n",
      "3110/3110 [==============================] - 0s 44us/sample - loss: 0.3440 - acc: 0.8334\n",
      "Epoch 83/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.3188 - acc: 0.8514\n",
      "Epoch 84/100\n",
      "3110/3110 [==============================] - 0s 44us/sample - loss: 0.3294 - acc: 0.8479\n",
      "Epoch 85/100\n",
      "3110/3110 [==============================] - 0s 44us/sample - loss: 0.3261 - acc: 0.8540\n",
      "Epoch 86/100\n",
      "3110/3110 [==============================] - 0s 43us/sample - loss: 0.3159 - acc: 0.8537\n",
      "Epoch 87/100\n",
      "3110/3110 [==============================] - 0s 44us/sample - loss: 0.3256 - acc: 0.8447\n",
      "Epoch 88/100\n",
      "3110/3110 [==============================] - 0s 44us/sample - loss: 0.3214 - acc: 0.8534\n",
      "Epoch 89/100\n",
      "3110/3110 [==============================] - 0s 44us/sample - loss: 0.3249 - acc: 0.8469\n",
      "Epoch 90/100\n",
      "3110/3110 [==============================] - 0s 44us/sample - loss: 0.3201 - acc: 0.8479\n",
      "Epoch 91/100\n",
      "3110/3110 [==============================] - 0s 44us/sample - loss: 0.3128 - acc: 0.8537\n",
      "Epoch 92/100\n",
      "3110/3110 [==============================] - 0s 44us/sample - loss: 0.3028 - acc: 0.8588\n",
      "Epoch 93/100\n",
      "3110/3110 [==============================] - 0s 43us/sample - loss: 0.3069 - acc: 0.8627\n",
      "Epoch 94/100\n",
      "3110/3110 [==============================] - 0s 44us/sample - loss: 0.2960 - acc: 0.8633\n",
      "Epoch 95/100\n",
      "3110/3110 [==============================] - 0s 45us/sample - loss: 0.3040 - acc: 0.8617\n",
      "Epoch 96/100\n",
      "3110/3110 [==============================] - 0s 46us/sample - loss: 0.3068 - acc: 0.8595\n",
      "Epoch 97/100\n",
      "3110/3110 [==============================] - 0s 43us/sample - loss: 0.2971 - acc: 0.8643\n",
      "Epoch 98/100\n",
      "3110/3110 [==============================] - 0s 44us/sample - loss: 0.2940 - acc: 0.8633\n",
      "Epoch 99/100\n",
      "3110/3110 [==============================] - 0s 44us/sample - loss: 0.2985 - acc: 0.8646\n",
      "Epoch 100/100\n",
      "3110/3110 [==============================] - 0s 44us/sample - loss: 0.2956 - acc: 0.8637\n",
      "778/778 [==============================] - 0s 194us/sample - loss: 0.8045 - acc: 0.7211\n",
      "[0.8045340180397034, 0.7210797]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.69      0.70       370\n",
      "           1       0.73      0.75      0.74       408\n",
      "\n",
      "    accuracy                           0.72       778\n",
      "   macro avg       0.72      0.72      0.72       778\n",
      "weighted avg       0.72      0.72      0.72       778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred4=ANN(X_train,y_train,X_test,y_test,'binary_crossentropy',-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "778"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(815,)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_final=y_pred1.copy()\n",
    "\n",
    "for i in range(len(y_pred1)):\n",
    "    n_ones=y_pred1[i]+y_pred2[i]+y_pred3[i]\n",
    "    if n_ones>1:\n",
    "        y_pred_final[i]=1\n",
    "    else:\n",
    "        y_pred_final[i]=0\n",
    "\n",
    "y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81       408\n",
      "           1       0.86      0.71      0.78       407\n",
      "\n",
      "    accuracy                           0.80       815\n",
      "   macro avg       0.81      0.80      0.79       815\n",
      "weighted avg       0.81      0.80      0.79       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
